{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import string\n",
    "import json\n",
    "import os\n",
    "\n",
    "from enum import Enum\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRTY_BASE_PATH = \"./Datasets/Real/BankChurners/DirtyBase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_random_string():\n",
    "    return ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyFunctions:\n",
    "    @staticmethod\n",
    "    def columns_swap(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "        columnA = columns[0]\n",
    "        columnB = columns[1]\n",
    "        \n",
    "        df = df.copy()\n",
    "        tmp = df[columnA].copy()\n",
    "        df[columnA] = df[columnB]\n",
    "        df[columnB] = tmp\n",
    "\n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def columns_partial_swap(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "        columnA = columns[0]\n",
    "        columnB = columns[1]\n",
    "        \n",
    "        df = df.copy()\n",
    "        swap_starting_at = df.shape[0] // 2\n",
    "        tmp = df[columnA].iloc[swap_starting_at:].copy()\n",
    "        df[columnA].iloc[swap_starting_at:] = df[columnB].iloc[swap_starting_at:]\n",
    "        df[columnB].iloc[swap_starting_at:] = tmp\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def duplicates_influx(df: pd.DataFrame, columns: list, share=1/2) -> pd.DataFrame:\n",
    "        columnA = columns[0]\n",
    "        \n",
    "        df = df.copy()\n",
    "        value_to_make_dupes = df[columnA].iat[0]\n",
    "        indices = np.random.choice(df.shape[0], int(df.shape[0] * share), replace=False)\n",
    "        df[columnA].iloc[indices] = value_to_make_dupes\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def nan_influx(df: pd.DataFrame, columns: list, share=1/2) -> pd.DataFrame:\n",
    "        columnA = columns[0]\n",
    "        \n",
    "        df = df.copy()\n",
    "        indices = np.random.choice(df.shape[0], int(df.shape[0] * share), replace=False)\n",
    "        df[columnA].iloc[indices] = None\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def random_influx(df: pd.DataFrame, columns: list, share=1/2) -> pd.DataFrame:\n",
    "        columnA = columns[0]\n",
    "        \n",
    "        df = df.copy()\n",
    "        indices = np.random.choice(df.shape[0], int(df.shape[0] * share), replace=False)\n",
    "        df[columnA].iloc[indices] = make_random_string()\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def numeric_variance_change(df: pd.DataFrame, columns: list, coef=2) -> pd.DataFrame:\n",
    "        columnA = columns[0]\n",
    "        \n",
    "        df = df.copy()\n",
    "        df[columnA] = df[columnA] * coef\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def numeric_mean_change(df: pd.DataFrame, columns: list, coef=0.5) -> pd.DataFrame:\n",
    "        columnA = columns[0]\n",
    "        \n",
    "        avg = df[columnA].mean()\n",
    "        \n",
    "        df = df.copy()\n",
    "        df[columnA] = (df[columnA] - avg) + avg * coef\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def categorical_new_category_influx(df: pd.DataFrame, columns: list, share=1/2) -> pd.DataFrame:\n",
    "        columnA = columns[0]\n",
    "        \n",
    "        uniqueVals = df[columnA].unique()\n",
    "        newVal = ''.join(uniqueVals)\n",
    "        \n",
    "        df = df.copy()\n",
    "        df[columnA].iloc[np.random.choice(int(df.shape[0] * share))] = newVal\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    @staticmethod\n",
    "    def categorical_category_miss(df: pd.DataFrame, columns: list) -> pd.DataFrame:\n",
    "        columnA = columns[0]\n",
    "        \n",
    "        unique_vals = df[columnA].unique()\n",
    "        miss_val = unique_vals[0]\n",
    "        fill_val = unique_vals[-1]\n",
    "        \n",
    "        df = df.copy()\n",
    "        df.loc[df[columnA] == miss_val, columnA] = fill_val\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def categorical_distribution_changed(df: pd.DataFrame, columns: list, random_seed=42) -> pd.DataFrame:\n",
    "        columnA = columns[0]\n",
    "        \n",
    "        unique_vals = df[columnA].unique()\n",
    "        sample_probas = None\n",
    "        \n",
    "        if len(unique_vals) == 1:\n",
    "            sample_probas = [1]\n",
    "        elif len(unique_vals) == 2:\n",
    "            sample_probas = [0.2, 0.8]\n",
    "        elif len(unique_vals) == 3:\n",
    "            sample_probas = [0.2, 0.5, 0.3]\n",
    "        elif len(unique_vals) == 4:\n",
    "            sample_probas = [0.2, 0.2, 0.2, 0.4]\n",
    "        else:\n",
    "            sample_probas = np.random.dirichlet(np.arange(1, len(unique_vals) + 1), 1).flatten()\n",
    "        \n",
    "        df = df.copy()\n",
    "        df[columnA] = np.random.choice(unique_vals, size=df.shape[0], p=sample_probas)\n",
    "        \n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = json.load(open('./Datasets/Real/BankChurners/metadata.json', 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERATE GROUP-LEVEL ANOMALY DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANOMALY_COLUMNS = {\n",
    "    1: ['Attrition_Flag', 'Gender', \"Education_Level\", \"Marital_Status\", 'Credit_Limit', 'Total_Revolving_Bal', 'Total_Trans_Amt'],\n",
    "    2: ['Avg_Utilization_Ratio', 'Card_Category', 'Customer_Age', 'Avg_Open_To_Buy', 'Customer_Age', 'Total_Trans_Amt'],\n",
    "    3: ['Avg_Utilization_Ratio', 'Card_Category', 'Customer_Age', 'Avg_Open_To_Buy', 'Total_Revolving_Bal', 'Total_Trans_Amt'],\n",
    "    4: ['Avg_Utilization_Ratio', 'Total_Revolving_Bal', 'Attrition_Flag', 'Dependent_count', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Ct_Chng_Q4_Q1', 'Months_on_book'],\n",
    "    5: ['Customer_Age', 'Total_Relationship_Count', 'Education_Level', 'Total_Amt_Chng_Q4_Q1', 'Marital_Status', 'Total_Revolving_Bal', 'Avg_Utilization_Ratio', 'Total_Ct_Chng_Q4_Q1'],\n",
    "    6: ['CLIENTNUM', 'Gender', 'Contacts_Count_12_mon', 'Dependent_count', 'Total_Relationship_Count', 'Credit_Limit', 'Avg_Utilization_Ratio', 'Total_Revolving_Bal'],\n",
    "    7: ['Total_Amt_Chng_Q4_Q1', 'CLIENTNUM', 'Gender', 'Months_on_book', 'Avg_Utilization_Ratio', 'Income_Category', 'Dependent_count', 'Card_Category'],\n",
    "    8: ['CLIENTNUM', 'Total_Revolving_Bal', 'Dependent_count', 'Education_Level', 'Contacts_Count_12_mon', 'Gender', 'Avg_Utilization_Ratio', 'Customer_Age'],\n",
    "    9: ['Credit_Limit', 'Marital_Status', 'Contacts_Count_12_mon', 'Customer_Age', 'Total_Relationship_Count', 'Months_on_book', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt'],\n",
    "    10: ['Months_Inactive_12_mon', 'Total_Amt_Chng_Q4_Q1', 'Dependent_count', 'Avg_Utilization_Ratio', 'Gender', 'Total_Revolving_Bal', 'Total_Trans_Amt', 'Months_on_book'],\n",
    "    11: ['Credit_Limit', 'Gender', 'Education_Level', 'Avg_Utilization_Ratio', 'Months_on_book', 'Total_Ct_Chng_Q4_Q1', 'Customer_Age', 'Total_Amt_Chng_Q4_Q1'],\n",
    "    12: ['Avg_Utilization_Ratio', 'Avg_Open_To_Buy', 'Total_Relationship_Count', 'Income_Category', 'Total_Revolving_Bal', 'Attrition_Flag', 'CLIENTNUM', 'Months_Inactive_12_mon'],\n",
    "    13: ['Credit_Limit', 'Customer_Age', 'Total_Relationship_Count', 'Total_Ct_Chng_Q4_Q1', 'Months_Inactive_12_mon', 'Marital_Status', 'Gender', 'Months_on_book'],\n",
    "    14: ['Months_Inactive_12_mon', 'Total_Relationship_Count', 'Credit_Limit', 'Gender', 'Contacts_Count_12_mon', 'Total_Trans_Amt', 'Dependent_count', 'Total_Ct_Chng_Q4_Q1'],\n",
    "    15: ['Total_Relationship_Count', 'CLIENTNUM', 'Income_Category', 'Dependent_count', 'Card_Category', 'Attrition_Flag', 'Gender', 'Credit_Limit']\n",
    "}\n",
    "\n",
    "ANOMALY_TRANSFORMS = {\n",
    "    # ['Attrition_Flag', 'Gender', \"Education_Level\", \"Marital_Status\", 'Credit_Limit', 'Total_Revolving_Bal', 'Total_Trans_Amt']\n",
    "    1: [\n",
    "        (partial(AnomalyFunctions.categorical_category_miss, columns=[\"Attrition_Flag\"])),\n",
    "        (partial(AnomalyFunctions.categorical_category_miss, columns=[\"Gender\"])),\n",
    "        (partial(AnomalyFunctions.columns_swap, columns=[\"Education_Level\", \"Marital_Status\"])),\n",
    "        (partial(AnomalyFunctions.nan_influx, columns=[\"Credit_Limit\"])),\n",
    "        (partial(AnomalyFunctions.numeric_mean_change, columns=[\"Total_Revolving_Bal\"])),\n",
    "        (partial(AnomalyFunctions.numeric_variance_change, columns=[\"Total_Trans_Amt\"])),\n",
    "    ],\n",
    "    # ['Avg_Utilization_Ratio', 'Card_Category', 'Customer_Age', 'Avg_Open_To_Buy', 'Customer_Age', 'Total_Trans_Amt']\n",
    "    2: [\n",
    "        (partial(AnomalyFunctions.numeric_mean_change, columns=[\"Avg_Utilization_Ratio\"], coef=1.5)),\n",
    "        (partial(AnomalyFunctions.categorical_category_miss, columns=[\"Card_Category\"])),\n",
    "        (partial(AnomalyFunctions.numeric_variance_change, columns=[\"Customer_Age\"], coef=0.5)),\n",
    "        (partial(AnomalyFunctions.random_influx, columns=[\"Avg_Open_To_Buy\"])),\n",
    "        (partial(AnomalyFunctions.duplicates_influx, columns=[\"Customer_Age\"])),\n",
    "        (partial(AnomalyFunctions.categorical_category_miss, columns=[\"Total_Trans_Amt\"])),\n",
    "    ],\n",
    "    # ['Avg_Utilization_Ratio', 'Card_Category', 'Customer_Age', 'Avg_Open_To_Buy', 'Total_Revolving_Bal', 'Total_Trans_Amt']\n",
    "    3: [\n",
    "        (partial(AnomalyFunctions.numeric_mean_change, columns=[\"Avg_Utilization_Ratio\"], coef=1.5)),\n",
    "        (partial(AnomalyFunctions.categorical_category_miss, columns=[\"Card_Category\"])),\n",
    "        (partial(AnomalyFunctions.numeric_variance_change, columns=[\"Customer_Age\"], coef=0.5)),\n",
    "        (partial(AnomalyFunctions.random_influx, columns=[\"Avg_Open_To_Buy\"])),\n",
    "        (partial(AnomalyFunctions.duplicates_influx, columns=[\"Total_Revolving_Bal\"])),\n",
    "        (partial(AnomalyFunctions.categorical_category_miss, columns=[\"Total_Trans_Amt\"])),\n",
    "    ], \n",
    "    # ['Avg_Utilization_Ratio', 'Total_Revolving_Bal', 'Attrition_Flag', 'Dependent_count', 'Avg_Open_To_Buy', 'Total_Amt_Chng_Q4_Q1', 'Total_Ct_Chng_Q4_Q1', 'Months_on_book']\n",
    "    4: [\n",
    "        (partial(AnomalyFunctions.nan_influx, columns=[\"Avg_Utilization_Ratio\"])),\n",
    "        (partial(AnomalyFunctions.random_influx, columns=[\"Total_Revolving_Bal\"])),\n",
    "        (partial(AnomalyFunctions.categorical_new_category_influx, columns=[\"Attrition_Flag\"])),\n",
    "        (partial(AnomalyFunctions.columns_partial_swap, columns=[\"Dependent_count\", \"Avg_Open_To_Buy\"])),\n",
    "        (partial(AnomalyFunctions.columns_swap, columns=[\"Total_Amt_Chng_Q4_Q1\", \"Total_Ct_Chng_Q4_Q1\"])),\n",
    "        (partial(AnomalyFunctions.numeric_mean_change, columns=[\"Months_on_book\"], coef=1.2)),\n",
    "    ],\n",
    "    # ['Customer_Age', 'Total_Relationship_Count', 'Education_Level', 'Total_Amt_Chng_Q4_Q1', 'Marital_Status', 'Total_Revolving_Bal', 'Avg_Utilization_Ratio', 'Total_Ct_Chng_Q4_Q1']\n",
    "    5: [\n",
    "        (partial(AnomalyFunctions.columns_swap, columns=[\"Customer_Age\", \"Total_Relationship_Count\"])),\n",
    "        (partial(AnomalyFunctions.categorical_new_category_influx, columns=[\"Education_Level\"])),\n",
    "        (partial(AnomalyFunctions.columns_partial_swap, columns=[\"Total_Amt_Chng_Q4_Q1\", \"Marital_Status\"])),\n",
    "        (partial(AnomalyFunctions.numeric_variance_change, columns=[\"Total_Revolving_Bal\"], coef=1.2)),\n",
    "        (partial(AnomalyFunctions.random_influx, columns=[\"Avg_Utilization_Ratio\"])),\n",
    "        (partial(AnomalyFunctions.numeric_variance_change, columns=[\"Total_Ct_Chng_Q4_Q1\"], coef=0.8))\n",
    "    ],\n",
    "    # ['CLIENTNUM', 'Gender', 'Contacts_Count_12_mon', 'Dependent_count', 'Total_Relationship_Count', 'Credit_Limit', 'Avg_Utilization_Ratio', 'Total_Revolving_Bal']\n",
    "    6: [\n",
    "        (partial(AnomalyFunctions.columns_partial_swap, columns=['CLIENTNUM', 'Gender'])),\n",
    "        (partial(AnomalyFunctions.nan_influx, columns=['Contacts_Count_12_mon'])),\n",
    "        (partial(AnomalyFunctions.columns_partial_swap, columns=['Dependent_count', 'Total_Relationship_Count'])),\n",
    "        (partial(AnomalyFunctions.random_influx, columns=['Credit_Limit'])),\n",
    "        (partial(AnomalyFunctions.numeric_variance_change, columns=['Avg_Utilization_Ratio'], coef=2.0)),\n",
    "        (partial(AnomalyFunctions.numeric_variance_change, columns=['Total_Revolving_Bal'], coef=1.2))\n",
    "    ],\n",
    "    # ['Total_Amt_Chng_Q4_Q1', 'CLIENTNUM', 'Gender', 'Months_on_book', 'Avg_Utilization_Ratio', 'Income_Category', 'Dependent_count', 'Card_Category']\n",
    "    7: [\n",
    "        (partial(AnomalyFunctions.numeric_mean_change, columns=['Total_Amt_Chng_Q4_Q1'], coef=0.3)),\n",
    "        (partial(AnomalyFunctions.random_influx, columns=['CLIENTNUM'])),\n",
    "        (partial(AnomalyFunctions.categorical_distribution_changed, columns=['Gender'])),\n",
    "        (partial(AnomalyFunctions.columns_swap, columns=['Months_on_book', 'Avg_Utilization_Ratio'])),\n",
    "        (partial(AnomalyFunctions.columns_swap, columns=['Income_Category', 'Dependent_count'])),\n",
    "        (partial(AnomalyFunctions.duplicates_influx, columns=['Card_Category']))\n",
    "    ],\n",
    "    # ['CLIENTNUM', 'Total_Revolving_Bal', 'Dependent_count', 'Education_Level', 'Contacts_Count_12_mon', 'Gender', 'Avg_Utilization_Ratio', 'Customer_Age']\n",
    "    8: [\n",
    "        (partial(AnomalyFunctions.duplicates_influx, columns=['CLIENTNUM'])),\n",
    "        (partial(AnomalyFunctions.nan_influx, columns=['Total_Revolving_Bal'])),\n",
    "        (partial(AnomalyFunctions.columns_partial_swap, columns=['Dependent_count', 'Education_Level'])),\n",
    "        (partial(AnomalyFunctions.columns_swap, columns=['Contacts_Count_12_mon', 'Gender'])),\n",
    "        (partial(AnomalyFunctions.numeric_variance_change, columns=['Avg_Utilization_Ratio'], coef=0.5)),\n",
    "        (partial(AnomalyFunctions.numeric_mean_change, columns=['Customer_Age'], coef=0.9))\n",
    "    ],\n",
    "    # ['Credit_Limit', 'Marital_Status', 'Contacts_Count_12_mon', 'Customer_Age', 'Total_Relationship_Count', 'Months_on_book', 'Total_Amt_Chng_Q4_Q1', 'Total_Trans_Amt']\n",
    "    9: [\n",
    "        (partial(AnomalyFunctions.numeric_mean_change, columns=['Credit_Limit'])),\n",
    "        (partial(AnomalyFunctions.nan_influx, columns=['Marital_Status'])),\n",
    "        (partial(AnomalyFunctions.columns_swap, columns=['Contacts_Count_12_mon', 'Customer_Age'])),\n",
    "        (partial(AnomalyFunctions.columns_partial_swap, columns=['Total_Relationship_Count', 'Months_on_book'])),\n",
    "        (partial(AnomalyFunctions.numeric_mean_change, columns=['Total_Amt_Chng_Q4_Q1'])),\n",
    "        (partial(AnomalyFunctions.nan_influx, columns=['Total_Trans_Amt']))\n",
    "    ],\n",
    "    # ['Months_Inactive_12_mon', 'Total_Amt_Chng_Q4_Q1', 'Dependent_count', 'Avg_Utilization_Ratio', 'Gender', 'Total_Revolving_Bal', 'Total_Trans_Amt', 'Months_on_book']\n",
    "    10: [\n",
    "        (partial(AnomalyFunctions.columns_swap, columns=['Months_Inactive_12_mon', 'Total_Amt_Chng_Q4_Q1'])),\n",
    "        (partial(AnomalyFunctions.numeric_mean_change, columns=['Dependent_count'], coef=0.7)),\n",
    "        (partial(AnomalyFunctions.numeric_mean_change, columns=['Avg_Utilization_Ratio'], coef=0.9)),\n",
    "        (partial(AnomalyFunctions.categorical_distribution_changed, columns=['Gender'])),\n",
    "        (partial(AnomalyFunctions.columns_swap, columns=['Total_Revolving_Bal', 'Total_Trans_Amt'])),\n",
    "        (partial(AnomalyFunctions.numeric_mean_change, columns=['Months_on_book'], coef=1.4))\n",
    "    ],\n",
    "    # ['Credit_Limit', 'Gender', 'Education_Level', 'Avg_Utilization_Ratio', 'Months_on_book', 'Total_Ct_Chng_Q4_Q1', 'Customer_Age', 'Total_Amt_Chng_Q4_Q1']\n",
    "    11: [\n",
    "        (partial(AnomalyFunctions.random_influx, columns=['Credit_Limit'])),\n",
    "        (partial(AnomalyFunctions.columns_partial_swap, columns=['Gender', 'Education_Level'])),\n",
    "        (partial(AnomalyFunctions.nan_influx, columns=['Avg_Utilization_Ratio'])),\n",
    "        (partial(AnomalyFunctions.columns_partial_swap, columns=['Months_on_book', 'Total_Ct_Chng_Q4_Q1'])),\n",
    "        (partial(AnomalyFunctions.random_influx, columns=['Customer_Age'])),\n",
    "        (partial(AnomalyFunctions.nan_influx, columns=['Total_Amt_Chng_Q4_Q1']))\n",
    "    ], \n",
    "    # ['Avg_Utilization_Ratio', 'Avg_Open_To_Buy', 'Total_Relationship_Count', 'Income_Category', 'Total_Revolving_Bal', 'Attrition_Flag', 'CLIENTNUM', 'Months_Inactive_12_mon']\n",
    "    12: [\n",
    "        (partial(AnomalyFunctions.columns_partial_swap, columns=['Avg_Utilization_Ratio', 'Avg_Open_To_Buy'])),\n",
    "        (partial(AnomalyFunctions.numeric_variance_change, columns=['Total_Relationship_Count'], coef=1.2)),\n",
    "        (partial(AnomalyFunctions.nan_influx, columns=['Income_Category'])),\n",
    "        (partial(AnomalyFunctions.random_influx, columns=['Total_Revolving_Bal'])),\n",
    "        (partial(AnomalyFunctions.columns_partial_swap, columns=['Attrition_Flag', 'CLIENTNUM'])),\n",
    "        (partial(AnomalyFunctions.numeric_variance_change, columns=['Months_Inactive_12_mon'], coef=2.5))\n",
    "    ], \n",
    "    # ['Credit_Limit', 'Customer_Age', 'Total_Relationship_Count', 'Total_Ct_Chng_Q4_Q1', 'Months_Inactive_12_mon', 'Marital_Status', 'Gender', 'Months_on_book']\n",
    "    13: [\n",
    "        (partial(AnomalyFunctions.nan_influx, columns=['Credit_Limit'])),\n",
    "        (partial(AnomalyFunctions.random_influx, columns=['Customer_Age'])),\n",
    "        (partial(AnomalyFunctions.columns_partial_swap, columns=['Total_Relationship_Count', 'Total_Ct_Chng_Q4_Q1'])),\n",
    "        (partial(AnomalyFunctions.random_influx, columns=['Months_Inactive_12_mon'])),\n",
    "        (partial(AnomalyFunctions.columns_swap, columns=['Marital_Status', 'Gender'])),\n",
    "        (partial(AnomalyFunctions.numeric_mean_change, columns=['Months_on_book'], coef=1.1))\n",
    "    ],\n",
    "    # ['Months_Inactive_12_mon', 'Total_Relationship_Count', 'Credit_Limit', 'Gender', 'Contacts_Count_12_mon', 'Total_Trans_Amt', 'Dependent_count', 'Total_Ct_Chng_Q4_Q1']\n",
    "    14: [\n",
    "        (partial(AnomalyFunctions.numeric_mean_change, columns=['Months_Inactive_12_mon'], coef=0.7)),\n",
    "        (partial(AnomalyFunctions.columns_swap, columns=['Total_Relationship_Count', 'Credit_Limit'])),\n",
    "        (partial(AnomalyFunctions.categorical_new_category_influx, columns=['Gender'])),\n",
    "        (partial(AnomalyFunctions.numeric_variance_change, columns=['Contacts_Count_12_mon'], coef=2.3)),\n",
    "        (partial(AnomalyFunctions.columns_swap, columns=['Total_Trans_Amt', 'Dependent_count'])),\n",
    "        (partial(AnomalyFunctions.nan_influx, columns=['Total_Ct_Chng_Q4_Q1']))\n",
    "    ],\n",
    "    # ['Total_Relationship_Count', 'CLIENTNUM', 'Income_Category', 'Dependent_count', 'Card_Category', 'Attrition_Flag', 'Gender', 'Credit_Limit']\n",
    "    15: [\n",
    "        (partial(AnomalyFunctions.numeric_variance_change, columns=['Total_Relationship_Count'])),\n",
    "        (partial(AnomalyFunctions.columns_swap, columns=['CLIENTNUM', 'Income_Category'])),\n",
    "        (partial(AnomalyFunctions.nan_influx, columns=['Dependent_count'])),\n",
    "        (partial(AnomalyFunctions.categorical_distribution_changed, columns=['Card_Category'])),\n",
    "        (partial(AnomalyFunctions.categorical_distribution_changed, columns=['Attrition_Flag'])),\n",
    "        (partial(AnomalyFunctions.columns_swap, columns=['Gender', 'Credit_Limit']))\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRTY_GROUP_PATH = \"./Datasets/Real/BankChurners/DirtyGroup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_dataframes = list()\n",
    "for fname in os.listdir(DIRTY_BASE_PATH):\n",
    "    if fname.endswith(\".csv\"):\n",
    "        dirty_dataframes.append(pd.read_csv(f'{DIRTY_BASE_PATH}/{fname}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(anomaly_columns):\n",
    "    indices = np.argwhere(dirty_dataframes[0].columns.isin(anomaly_columns)).squeeze()\n",
    "    result = np.zeros(dirty_dataframes[0].columns.shape[0])\n",
    "    result[indices] = 1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ppogorelov/VirtualEnv/v2/lib/python3.7/site-packages/pandas/core/indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/ppogorelov/VirtualEnv/v2/lib/python3.7/site-packages/pandas/core/indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/ppogorelov/VirtualEnv/v2/lib/python3.7/site-packages/pandas/core/indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/ppogorelov/VirtualEnv/v2/lib/python3.7/site-packages/pandas/core/indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/ppogorelov/VirtualEnv/v2/lib/python3.7/site-packages/pandas/core/indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/ppogorelov/VirtualEnv/v2/lib/python3.7/site-packages/pandas/core/indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/ppogorelov/VirtualEnv/v2/lib/python3.7/site-packages/pandas/core/indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/ppogorelov/VirtualEnv/v2/lib/python3.7/site-packages/pandas/core/indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/ppogorelov/VirtualEnv/v2/lib/python3.7/site-packages/pandas/core/indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/ppogorelov/VirtualEnv/v2/lib/python3.7/site-packages/pandas/core/indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/ppogorelov/VirtualEnv/v2/lib/python3.7/site-packages/pandas/core/indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/ppogorelov/VirtualEnv/v2/lib/python3.7/site-packages/pandas/core/indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/ppogorelov/VirtualEnv/v2/lib/python3.7/site-packages/pandas/core/indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/ppogorelov/VirtualEnv/v2/lib/python3.7/site-packages/pandas/core/indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/ppogorelov/VirtualEnv/v2/lib/python3.7/site-packages/pandas/core/indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/ppogorelov/VirtualEnv/v2/lib/python3.7/site-packages/pandas/core/indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/ppogorelov/VirtualEnv/v2/lib/python3.7/site-packages/pandas/core/indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/ppogorelov/VirtualEnv/v2/lib/python3.7/site-packages/pandas/core/indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/ppogorelov/VirtualEnv/v2/lib/python3.7/site-packages/pandas/core/indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/ppogorelov/VirtualEnv/v2/lib/python3.7/site-packages/pandas/core/indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n",
      "/Users/ppogorelov/VirtualEnv/v2/lib/python3.7/site-packages/pandas/core/indexing.py:1636: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_block(indexer, value, name)\n"
     ]
    }
   ],
   "source": [
    "dataset_count = 0\n",
    "labels = []\n",
    "\n",
    "for key, anomalies in ANOMALY_TRANSFORMS.items():\n",
    "    directory_path = f\"{DIRTY_GROUP_PATH}/anomaly_{key}/\"\n",
    "    os.makedirs(directory_path, exist_ok=True)\n",
    "    \n",
    "    json.dump(ANOMALY_COLUMNS[key], open(f\"{directory_path}labels.json\", \"w\"))\n",
    "    \n",
    "    for i, ddframe in enumerate(dirty_dataframes):\n",
    "        ddframe_tmp = ddframe.copy()\n",
    "        for anomaly in anomalies:\n",
    "            ddframe_tmp = anomaly(ddframe_tmp)\n",
    "        \n",
    "        ddframe_tmp.to_csv(f\"{directory_path}dataset_{i}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERATE ANOMALY-LEVEL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANOMALY_WITH_TYPES = [\n",
    "    ('duplicates_influx', 'any', AnomalyFunctions.duplicates_influx),\n",
    "    ('nan_influx', 'any', AnomalyFunctions.nan_influx),\n",
    "    ('random_influx', 'any', AnomalyFunctions.random_influx),\n",
    "    ('numeric_variance_change', 'numeric', AnomalyFunctions.numeric_variance_change),\n",
    "    ('numeric_mean_change', 'numeric', AnomalyFunctions.numeric_mean_change),\n",
    "    ('numeric_variance_change', 'numeric', AnomalyFunctions.numeric_variance_change),\n",
    "    ('numeric_mean_change', 'numeric', AnomalyFunctions.numeric_mean_change),\n",
    "    ('numeric_variance_change', 'numeric', AnomalyFunctions.numeric_variance_change),\n",
    "    ('numeric_mean_change', 'numeric', AnomalyFunctions.numeric_mean_change),\n",
    "    ('categorical_new_category_influx', 'categorical', AnomalyFunctions.categorical_new_category_influx),\n",
    "    ('categorical_category_miss', 'categorical', AnomalyFunctions.categorical_category_miss),\n",
    "    ('categorical_distribution_changed', 'categorical', AnomalyFunctions.categorical_distribution_changed),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRTY_SINGLE_ANOMALY_PATH = \"./Datasets/Real/BankChurners/DirtySingleAnomaly\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ddframe in enumerate(dirty_dataframes):\n",
    "    for n, t, f in ANOMALY_WITH_TYPES:\n",
    "        savedir = f\"{DIRTY_SINGLE_ANOMALY_PATH}/{t}/{n}\"\n",
    "        \n",
    "        os.makedirs(savedir, exist_ok=True)\n",
    "        ddframe = ddframe.copy()\n",
    "        if t == 'any':\n",
    "            for c in metadata.keys():\n",
    "                os.makedirs(f\"{savedir}/{c}\", exist_ok=True)\n",
    "                \n",
    "                np.save(f\"{savedir}/{c}/{i}.npy\", f(ddframe, columns=[c])[c].values)\n",
    "        else:\n",
    "            for c, ct in metadata.items():\n",
    "                if ct == t:\n",
    "                    os.makedirs(f\"{savedir}/{c}\", exist_ok=True)\n",
    "                    np.save(f\"{savedir}/{c}/{i}.npy\", f(ddframe, columns=[c])[c].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERATE COLUMN-LEVEL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRTY_SINGLE_COLUMN_PATH = \"./Datasets/Real/BankChurners/DirtySingleColumn\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, ddframe in enumerate(dirty_dataframes):\n",
    "    for c, ct in metadata.items():\n",
    "        savedir = f\"{DIRTY_SINGLE_COLUMN_PATH}/{c}\"\n",
    "        os.makedirs(savedir, exist_ok=True)\n",
    "        \n",
    "        for j, (n, t, f) in enumerate(ANOMALY_WITH_TYPES):\n",
    "            ddframe = ddframe.copy()\n",
    "            if t == 'any':\n",
    "                np.save(f\"{savedir}/{i}_{j}.npy\", f(ddframe, columns=[c])[c].values)\n",
    "            else:\n",
    "                if ct == t:\n",
    "                    np.save(f\"{savedir}/{i}_{j}.npy\", f(ddframe, columns=[c])[c].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERATE ANOMALY-SENSITIVITY DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANOMALY_WITH_TYPES = [\n",
    "    ('duplicates_influx_0.05', 'any', partial(AnomalyFunctions.duplicates_influx, share=0.05)),\n",
    "    ('duplicates_influx_0.1', 'any', partial(AnomalyFunctions.duplicates_influx, share=0.1)),\n",
    "    ('duplicates_influx_0.2', 'any', partial(AnomalyFunctions.duplicates_influx, share=0.2)),\n",
    "    ('duplicates_influx_0.3', 'any', partial(AnomalyFunctions.duplicates_influx, share=0.3)),\n",
    "    ('duplicates_influx_0.5', 'any', partial(AnomalyFunctions.duplicates_influx, share=0.5)),\n",
    "    ('duplicates_influx_0.9', 'any', partial(AnomalyFunctions.duplicates_influx, share=0.9)),    \n",
    "    \n",
    "    ('random_influx', 'any', AnomalyFunctions.random_influx),\n",
    "    ('numeric_variance_change_0.7', 'numeric', partial(AnomalyFunctions.numeric_variance_change, coef=0.7)),\n",
    "    ('numeric_mean_change_0.7', 'numeric', partial(AnomalyFunctions.numeric_mean_change, coef=0.7)),\n",
    "    ('numeric_variance_change_1.3', 'numeric', partial(AnomalyFunctions.numeric_variance_change, coef=1.3)),\n",
    "    ('numeric_mean_change_1.3', 'numeric', partial(AnomalyFunctions.numeric_mean_change, coef=1.3)),\n",
    "    ('numeric_variance_change_0.9', 'numeric', partial(AnomalyFunctions.numeric_variance_change, coef=0.9)),\n",
    "    ('numeric_mean_change_0.9', 'numeric', partial(AnomalyFunctions.numeric_mean_change, coef=0.9)),\n",
    "    ('categorical_new_category_influx', 'categorical', AnomalyFunctions.categorical_new_category_influx),\n",
    "    ('categorical_category_miss', 'categorical', AnomalyFunctions.categorical_category_miss),\n",
    "    ('categorical_distribution_changed', 'categorical', AnomalyFunctions.categorical_distribution_changed),\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
