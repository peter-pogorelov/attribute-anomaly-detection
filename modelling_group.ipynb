{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.stats import entropy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRTY_GROUP_FEATURIZED_PATH = \"./Datasets/Featurized/BankChurners/DirtyGroup\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pickle.load(open(f\"{DIRTY_GROUP_FEATURIZED_PATH}/DirtyGroup.pickle\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# META MODEL INTERFACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.base import clone as clone_estimator\n",
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaNoveltyModel:\n",
    "    def __init__(self, base_clr, base_scaler):\n",
    "        self.base_clr = base_clr\n",
    "        self.base_scaler = base_scaler\n",
    "        self.estimators = dict()\n",
    "        self.scalers = dict()\n",
    "    \n",
    "    def fit(self, X, z):\n",
    "        sorted_by_column = sorted(zip(X, z), key=lambda x: x[-1])\n",
    "        \n",
    "        for (z_val, X_z) in groupby(sorted_by_column, key=lambda x: x[-1]):\n",
    "            X_, _ = zip(*X_z)\n",
    "            estimator = clone_estimator(self.base_clr, safe=True)\n",
    "            scaler = clone_estimator(self.base_scaler, safe=True)\n",
    "            x_ = scaler.fit_transform(X_)\n",
    "            estimator.fit(x_)\n",
    "            self.estimators[z_val] = estimator\n",
    "            self.scalers[z_val] = scaler\n",
    "    \n",
    "    def __predict(self, column, x):\n",
    "        check_is_fitted(self.scalers[column])\n",
    "        check_is_fitted(self.estimators[column])\n",
    "        \n",
    "        return self.estimators[column].predict(\n",
    "            self.scalers[column].transform(\n",
    "                np.atleast_2d(x)\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def __decision_function(self, column, x):\n",
    "        check_is_fitted(self.scalers[column])\n",
    "        check_is_fitted(self.estimators[column])\n",
    "        \n",
    "        if(hasattr(self.estimators[column], 'decision_function')):\n",
    "            return self.estimators[column].decision_function(\n",
    "                self.scalers[column].transform(\n",
    "                    np.atleast_2d(x)\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            raise Exception(f\"estimator for {column} has no decision_function\")\n",
    "            \n",
    "    def __apply_function(self, X, z, func):\n",
    "        i = list(range(len(z)))\n",
    "        sorted_by_column = sorted(zip(X, i, z), key=lambda x: x[-1])\n",
    "        \n",
    "        pred = np.zeros((len(z)))\n",
    "        \n",
    "        for (z_val, X_z) in groupby(sorted_by_column, key=lambda x: x[-1]):\n",
    "            X_, i_, _ = zip(*X_z)\n",
    "            pred[list(i_)] = func(z_val, X_)\n",
    "            \n",
    "        return np.array(pred)\n",
    "    \n",
    "    def predict(self, X, z):\n",
    "        return self.__apply_function(X, z, self.__predict)\n",
    "    \n",
    "    def decision_function(self, X, z):\n",
    "        return self.__apply_function(X, z, self.__decision_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaOutlierModel:\n",
    "    def __init__(self, base_clr, base_scaler):\n",
    "        self.base_clr = base_clr\n",
    "        self.base_scaler = base_scaler\n",
    "        self.estimators = dict()\n",
    "        self.scalers = dict()\n",
    "    \n",
    "    def __fit_predict(self, column, x):\n",
    "        return self.estimators[column].fit_predict(\n",
    "            self.scalers[column].fit_transform(\n",
    "                np.atleast_2d(x)\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def __fit_decision_function(self, column, x):\n",
    "        x_ = self.scalers[column].fit_transform(np.atleast_2d(x))\n",
    "        if(hasattr(self.estimators[column], 'decision_function')):\n",
    "            self.estimators[column].fit(x_)\n",
    "            return self.estimators[column].decision_function(x_)\n",
    "        elif isinstance(self.estimators[column], LocalOutlierFactor):\n",
    "            self.estimators[column].fit_predict(x_)\n",
    "            return self.estimators[column].negative_outlier_factor_\n",
    "        else:    \n",
    "            raise Exception(f\"estimator for {column} has no decision_function\")\n",
    "            \n",
    "    def __fit_apply(self, X, z, func):\n",
    "        i = list(range(len(z)))\n",
    "        sorted_by_column = sorted(zip(X, i, z), key=lambda x: x[-1])\n",
    "        \n",
    "        pred = np.zeros((len(z)))\n",
    "        \n",
    "        for (z_val, X_z) in groupby(sorted_by_column, key=lambda x: x[-1]):\n",
    "            self.estimators[z_val] = clone_estimator(self.base_clr, safe=True)\n",
    "            self.scalers[z_val] = clone_estimator(self.base_scaler, safe=True)\n",
    "            X_, i_, _ = zip(*X_z)\n",
    "            pred[list(i_)] = func(z_val, X_)\n",
    "            \n",
    "        return np.array(pred)\n",
    "    \n",
    "    def fit_predict(self, X, z):\n",
    "        return self.__fit_apply(X, z, self.__fit_predict)\n",
    "    \n",
    "    def fit_decision_function(self, X, z):\n",
    "        return self.__fit_apply(X, z, self.__fit_decision_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN / INFER NOVELTY DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = list()\n",
    "Z_train = list()\n",
    "\n",
    "for col, features in dataset['train'].items():\n",
    "    X, z = zip(*[(x[0], col) for x in features])\n",
    "    X_train += X\n",
    "    Z_train += list(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_control = list()\n",
    "Y_control = list()\n",
    "Z_control = list()\n",
    "\n",
    "for col, features in dataset['control'].items():\n",
    "    X, y, z = zip(*[(x[0], x[1], col) for x in features])\n",
    "    X_control += X\n",
    "    Y_control += y\n",
    "    Z_control += list(z)\n",
    "    \n",
    "Y_control = np.array(Y_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNDERSAMPLED EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms_novelty = {\n",
    "    'LocalOutlierFactorNovelty': LocalOutlierFactor(novelty=True),\n",
    "    'OneClassSVM_Linear': OneClassSVM(kernel='linear'),\n",
    "    'OneClassSVM_RBF': OneClassSVM()\n",
    "}\n",
    "\n",
    "algorithms_outlier = {\n",
    "    'LocalOutlierFactor': LocalOutlierFactor(novelty=False),\n",
    "    'IsolationForest': IsolationForest()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, counts = np.unique(Y_control, return_counts=True)\n",
    "\n",
    "NUM_NEGATIVES = counts[0]\n",
    "NUM_POSITIVES = counts[1]\n",
    "NUM_ITERATIONS = 10\n",
    "\n",
    "POSITIVE_LOC = np.argwhere(Y_control == True).squeeze()\n",
    "NEGATIVE_LOC = np.argwhere(Y_control == False).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_control_negatives = np.array(X_control, dtype='object')[NEGATIVE_LOC].tolist()\n",
    "Y_control_negatives = np.array(Y_control, dtype='object')[NEGATIVE_LOC].tolist()\n",
    "Z_control_negatives = np.array(Z_control, dtype='object')[NEGATIVE_LOC].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = dict()\n",
    "\n",
    "for algo_name, algo in algorithms_novelty.items():\n",
    "    results[algo_name] = {}\n",
    "    for i in range(NUM_ITERATIONS):\n",
    "        for positive_share in [0.01, 0.05, 0.1, 0.15, 0.2]:\n",
    "            num_positives = int(NUM_NEGATIVES / (1 - positive_share) - NUM_NEGATIVES)\n",
    "            new_positives = np.random.choice(POSITIVE_LOC, num_positives)\n",
    "\n",
    "            clr = MetaNoveltyModel(algo, StandardScaler())\n",
    "\n",
    "            clr.fit(X_train, Z_train)\n",
    "\n",
    "            X_control_positives = np.array(X_control, dtype='object')[new_positives].tolist()\n",
    "            Y_control_positives = np.array(Y_control, dtype='object')[new_positives].tolist()\n",
    "            Z_control_positives = np.array(Z_control, dtype='object')[new_positives].tolist()\n",
    "\n",
    "            X_control_new = X_control_negatives + X_control_positives\n",
    "            Y_control_new = np.r_[Y_control_negatives, Y_control_positives]\n",
    "            Z_control_new = Z_control_negatives + Z_control_positives\n",
    "\n",
    "            preds = clr.predict(X_control_new, Z_control_new)\n",
    "            anomaly_score = clr.decision_function(X_control_new, Z_control_new)\n",
    "            \n",
    "            if str(positive_share) not in results[algo_name]:\n",
    "                results[algo_name][str(positive_share)] = {}\n",
    "            \n",
    "            results[algo_name][str(positive_share)][i] = {\n",
    "                'true': (Y_control_new).squeeze(),\n",
    "                'pred': (preds == -1).astype(int).squeeze(),\n",
    "                'score': (-anomaly_score).squeeze()\n",
    "            }\n",
    "            \n",
    "for algo_name, algo in algorithms_outlier.items():\n",
    "    results[algo_name] = {}\n",
    "    for i in range(NUM_ITERATIONS):\n",
    "        for positive_share in [0.01, 0.05, 0.1, 0.15, 0.2]:\n",
    "            num_positives = int(NUM_NEGATIVES / (1 - positive_share) - NUM_NEGATIVES)\n",
    "            new_positives = np.random.choice(POSITIVE_LOC, num_positives)\n",
    "\n",
    "            clr = MetaOutlierModel(algo, StandardScaler())\n",
    "\n",
    "            X_control_positives = np.array(X_control, dtype='object')[new_positives].tolist()\n",
    "            Y_control_positives = np.array(Y_control, dtype='object')[new_positives].tolist()\n",
    "            Z_control_positives = np.array(Z_control, dtype='object')[new_positives].tolist()\n",
    "\n",
    "            X_control_new = X_control_negatives + X_control_positives\n",
    "            Y_control_new = np.r_[Y_control_negatives, Y_control_positives]\n",
    "            Z_control_new = Z_control_negatives + Z_control_positives\n",
    "\n",
    "            preds = clr.fit_predict(X_control_new, Z_control_new)\n",
    "            anomaly_score = clr.fit_decision_function(X_control_new, Z_control_new)\n",
    "            \n",
    "            if str(positive_share) not in results[algo_name]:\n",
    "                results[algo_name][str(positive_share)] = {}\n",
    "            \n",
    "            results[algo_name][str(positive_share)][i] = {\n",
    "                'true': (Y_control_new).squeeze(),\n",
    "                'pred': (preds == -1).astype(int).squeeze(),\n",
    "                'score': (-anomaly_score).squeeze()\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = list()\n",
    "for algo, algo_data in results.items():\n",
    "    for share, data_iters in algo_data.items():\n",
    "        precisions = []\n",
    "        recalls = []\n",
    "        aucs = []\n",
    "        \n",
    "        for i, data in data_iters.items():\n",
    "            precisions.append(precision_score(data['true'], data['pred']))\n",
    "            recalls.append(recall_score(data['true'], data['pred']))\n",
    "            aucs.append(roc_auc_score(data['true'], data['score']))\n",
    "            \n",
    "        metrics.append({\n",
    "            'algorithm': algo,\n",
    "            'positive_share': float(share),\n",
    "            'precision': np.mean(precisions),\n",
    "            'recall': np.mean(recalls),\n",
    "            'auc': np.mean(aucs)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>algorithm</th>\n",
       "      <th>positive_share</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.018385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.356378</td>\n",
       "      <td>0.981443</td>\n",
       "      <td>0.990596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.854126</td>\n",
       "      <td>0.966990</td>\n",
       "      <td>0.992570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.957476</td>\n",
       "      <td>0.931098</td>\n",
       "      <td>0.992453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IsolationForest</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.984667</td>\n",
       "      <td>0.899140</td>\n",
       "      <td>0.986904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LocalOutlierFactor</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.103639</td>\n",
       "      <td>0.961111</td>\n",
       "      <td>0.966132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LocalOutlierFactor</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.362286</td>\n",
       "      <td>0.944330</td>\n",
       "      <td>0.961704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LocalOutlierFactor</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.544185</td>\n",
       "      <td>0.935922</td>\n",
       "      <td>0.955804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LocalOutlierFactor</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.646173</td>\n",
       "      <td>0.937805</td>\n",
       "      <td>0.959190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LocalOutlierFactor</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.718224</td>\n",
       "      <td>0.906452</td>\n",
       "      <td>0.946247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LocalOutlierFactorNovelty</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.452960</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.980088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LocalOutlierFactorNovelty</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.815272</td>\n",
       "      <td>0.955670</td>\n",
       "      <td>0.980254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LocalOutlierFactorNovelty</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.904704</td>\n",
       "      <td>0.967961</td>\n",
       "      <td>0.985316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LocalOutlierFactorNovelty</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.937699</td>\n",
       "      <td>0.963720</td>\n",
       "      <td>0.984865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LocalOutlierFactorNovelty</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.955335</td>\n",
       "      <td>0.966022</td>\n",
       "      <td>0.984387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>OneClassSVM_Linear</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.010222</td>\n",
       "      <td>0.572222</td>\n",
       "      <td>0.574229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>OneClassSVM_Linear</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.050728</td>\n",
       "      <td>0.549485</td>\n",
       "      <td>0.549562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>OneClassSVM_Linear</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.102102</td>\n",
       "      <td>0.550485</td>\n",
       "      <td>0.545875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OneClassSVM_Linear</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.151830</td>\n",
       "      <td>0.544512</td>\n",
       "      <td>0.543550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>OneClassSVM_Linear</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.202875</td>\n",
       "      <td>0.545806</td>\n",
       "      <td>0.545811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>OneClassSVM_RBF</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.015893</td>\n",
       "      <td>0.983333</td>\n",
       "      <td>0.977622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>OneClassSVM_RBF</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.080691</td>\n",
       "      <td>0.991753</td>\n",
       "      <td>0.979368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>OneClassSVM_RBF</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.156208</td>\n",
       "      <td>0.984951</td>\n",
       "      <td>0.975234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>OneClassSVM_RBF</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.227515</td>\n",
       "      <td>0.984146</td>\n",
       "      <td>0.973740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>OneClassSVM_RBF</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.294858</td>\n",
       "      <td>0.985591</td>\n",
       "      <td>0.975545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    algorithm  positive_share  precision    recall       auc\n",
       "0             IsolationForest            0.01   0.018385  1.000000  0.999982\n",
       "1             IsolationForest            0.05   0.356378  0.981443  0.990596\n",
       "2             IsolationForest            0.10   0.854126  0.966990  0.992570\n",
       "3             IsolationForest            0.15   0.957476  0.931098  0.992453\n",
       "4             IsolationForest            0.20   0.984667  0.899140  0.986904\n",
       "5          LocalOutlierFactor            0.01   0.103639  0.961111  0.966132\n",
       "6          LocalOutlierFactor            0.05   0.362286  0.944330  0.961704\n",
       "7          LocalOutlierFactor            0.10   0.544185  0.935922  0.955804\n",
       "8          LocalOutlierFactor            0.15   0.646173  0.937805  0.959190\n",
       "9          LocalOutlierFactor            0.20   0.718224  0.906452  0.946247\n",
       "10  LocalOutlierFactorNovelty            0.01   0.452960  0.966667  0.980088\n",
       "11  LocalOutlierFactorNovelty            0.05   0.815272  0.955670  0.980254\n",
       "12  LocalOutlierFactorNovelty            0.10   0.904704  0.967961  0.985316\n",
       "13  LocalOutlierFactorNovelty            0.15   0.937699  0.963720  0.984865\n",
       "14  LocalOutlierFactorNovelty            0.20   0.955335  0.966022  0.984387\n",
       "15         OneClassSVM_Linear            0.01   0.010222  0.572222  0.574229\n",
       "16         OneClassSVM_Linear            0.05   0.050728  0.549485  0.549562\n",
       "17         OneClassSVM_Linear            0.10   0.102102  0.550485  0.545875\n",
       "18         OneClassSVM_Linear            0.15   0.151830  0.544512  0.543550\n",
       "19         OneClassSVM_Linear            0.20   0.202875  0.545806  0.545811\n",
       "20            OneClassSVM_RBF            0.01   0.015893  0.983333  0.977622\n",
       "21            OneClassSVM_RBF            0.05   0.080691  0.991753  0.979368\n",
       "22            OneClassSVM_RBF            0.10   0.156208  0.984951  0.975234\n",
       "23            OneClassSVM_RBF            0.15   0.227515  0.984146  0.973740\n",
       "24            OneClassSVM_RBF            0.20   0.294858  0.985591  0.975545"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics).sort_values(by=['algorithm', 'positive_share']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
